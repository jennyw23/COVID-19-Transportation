{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92a3cfac",
   "metadata": {},
   "source": [
    "# Part 5b: COVID-Dataset-Ranges\n",
    "\n",
    "This notebook does manual processing. \n",
    "\n",
    "#### nohup ../miniconda3/bin/python3 collect-03282020-05012020.py &\n",
    "#### collect-01182021-01242021.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "619231fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files in COVID Dataset before removing irrelevant dates: 20832\n",
      "Starting file name: https://raw.githubusercontent.com/echen102/COVID-19-TweetIDs/master/2020-01/coronavirus-tweet-id-2020-01-01-00.txt \n",
      "\n",
      "Total files in COVID Dataset after: 20330\n",
      "Starting file name: https://raw.githubusercontent.com/echen102/COVID-19-TweetIDs/master/2020-01/coronavirus-tweet-id-2020-01-21-22.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from datetime import date, timedelta\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "time_range = ['2020-01', '2020-02', '2020-03', '2020-04', '2020-05', '2020-06', '2020-07', '2020-08', '2020-09', '2020-10', '2020-11', '2020-12', \n",
    "            '2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12', \n",
    "            '2022-01', '2022-02', '2022-03', '2022-04']\n",
    "\n",
    "# def saveAllFileNames():\n",
    "#     filePaths = []\n",
    "#     # get directories\n",
    "#     directories = list(filter(os.path.isdir, os.listdir()))\n",
    "#     for fileDir in directories:\n",
    "#         if fileDir[0] != '.':\n",
    "#             for file in os.listdir(fileDir):\n",
    "#                 filePath = f'{fileDir}/{file}'\n",
    "#                 filePaths.append(filePath)\n",
    "    \n",
    "#     return filePaths\n",
    "\n",
    "def fetchAllTextFileURLs(time_range):\n",
    "    files = []\n",
    "    base_url = 'https://raw.githubusercontent.com/echen102/COVID-19-TweetIDs/master/'\n",
    "    prefix = 'coronavirus-tweet-id'\n",
    "    dates = list(range(1, 32)) # day 1 to 31\n",
    "    hours = list(range(24)) # hour 0 to 23\n",
    "    \n",
    "    for yyyyMM in time_range:\n",
    "        for date in dates:\n",
    "            date = f'0{date}' if date < 10 else f'{date}'\n",
    "            for hour in hours:\n",
    "                hour = f'0{hour}' if hour < 10 else f'{hour}'\n",
    "                fileURL = f'{base_url}{yyyyMM}/{prefix}-{yyyyMM}-{date}-{hour}.txt'\n",
    "                files.append(fileURL)\n",
    "\n",
    "                # print(fileURL)\n",
    "    \n",
    "    return files\n",
    "\n",
    "covidDataset = fetchAllTextFileURLs(time_range)\n",
    "print('Total files in COVID Dataset before removing irrelevant dates:', len(covidDataset))\n",
    "print('Starting file name:', covidDataset[0], '\\n')\n",
    "\n",
    "\n",
    "# data collection starts from 1/21/2020 at 22:00.\n",
    "covidDataset = covidDataset[502:]\n",
    "print('Total files in COVID Dataset after:', len(covidDataset))\n",
    "print('Starting file name:', covidDataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e40ee759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showDataCollectionStartEnd(x):\n",
    "    # y based on a 7 day collection period\n",
    "    y = x + 24 * 7 -1\n",
    "    \n",
    "    print(\"Start DATE\", covidDataset[x].split(\"/\")[7])\n",
    "    print(\"End DATE\", covidDataset[y].split(\"/\")[7])\n",
    "    print(\"x:\", covidDataset[x].split(\"/\")[7], \"\\ny+1:\", covidDataset[y+1].split(\"/\")[7], \"(since range requires +1)\")\n",
    "    print(f\"\\nStart VALUE={x}, \\nEnd VALUE={y+1}.\")\n",
    "    print(f'{x}-{y+1}')\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b605d5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DATE coronavirus-tweet-id-2020-12-28-00.txt\n",
      "End DATE coronavirus-tweet-id-2021-01-03-23.txt\n",
      "x: coronavirus-tweet-id-2020-12-28-00.txt \n",
      "y+1: coronavirus-tweet-id-2021-01-04-00.txt (since range requires +1)\n",
      "\n",
      "Start VALUE=8330, \n",
      "End VALUE=8498.\n"
     ]
    }
   ],
   "source": [
    "X = 8330\n",
    "# 6 days + 23 hours later... x + 24 * 7 - 1\n",
    "# Y = 8497\n",
    "showDataCollectionStartEnd(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5456e345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DATE coronavirus-tweet-id-2021-01-18-00.txt\n",
      "End DATE coronavirus-tweet-id-2021-01-24-23.txt\n",
      "x: coronavirus-tweet-id-2021-01-18-00.txt \n",
      "y+1: coronavirus-tweet-id-2021-01-25-00.txt (since range requires +1)\n",
      "\n",
      "Start VALUE=8834, \n",
      "End VALUE=9002.\n"
     ]
    }
   ],
   "source": [
    "X = 8834\n",
    "showDataCollectionStartEnd(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75f5bab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DATE coronavirus-tweet-id-2021-02-08-00.txt\n",
      "End DATE coronavirus-tweet-id-2021-02-14-23.txt\n",
      "x: coronavirus-tweet-id-2021-02-08-00.txt \n",
      "y+1: coronavirus-tweet-id-2021-02-15-00.txt (since range requires +1)\n",
      "\n",
      "Start VALUE=9338, \n",
      "End VALUE=9506.\n"
     ]
    }
   ],
   "source": [
    "X = 9338\n",
    "showDataCollectionStartEnd(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1b9c1ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DATE coronavirus-tweet-id-2021-02-22-00.txt\n",
      "End DATE coronavirus-tweet-id-2021-02-28-23.txt\n",
      "x: coronavirus-tweet-id-2021-02-22-00.txt \n",
      "y+1: coronavirus-tweet-id-2021-02-29-00.txt (since range requires +1)\n",
      "\n",
      "Start VALUE=9674, \n",
      "End VALUE=9842.\n"
     ]
    }
   ],
   "source": [
    "X = 9674\n",
    "showDataCollectionStartEnd(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bf317e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DATE coronavirus-tweet-id-2021-03-01-00.txt\n",
      "End DATE coronavirus-tweet-id-2021-03-07-23.txt\n",
      "x: coronavirus-tweet-id-2021-03-01-00.txt \n",
      "y+1: coronavirus-tweet-id-2021-03-08-00.txt (since range requires +1)\n",
      "\n",
      "Start VALUE=9914, \n",
      "End VALUE=10082.\n"
     ]
    }
   ],
   "source": [
    "X = 9914\n",
    "showDataCollectionStartEnd(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "947f3d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DATE coronavirus-tweet-id-2021-03-15-00.txt\n",
      "End DATE coronavirus-tweet-id-2021-03-21-23.txt\n",
      "x: coronavirus-tweet-id-2021-03-15-00.txt \n",
      "y+1: coronavirus-tweet-id-2021-03-22-00.txt (since range requires +1)\n",
      "\n",
      "Start VALUE=10250, \n",
      "End VALUE=10418.\n"
     ]
    }
   ],
   "source": [
    "X = 10250\n",
    "showDataCollectionStartEnd(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0c3e41c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DATE coronavirus-tweet-id-2021-04-05-00.txt\n",
      "End DATE coronavirus-tweet-id-2021-04-11-23.txt\n",
      "x: coronavirus-tweet-id-2021-04-05-00.txt \n",
      "y+1: coronavirus-tweet-id-2021-04-12-00.txt (since range requires +1)\n",
      "\n",
      "Start VALUE=10754, \n",
      "End VALUE=10922.\n"
     ]
    }
   ],
   "source": [
    "X = 10754\n",
    "showDataCollectionStartEnd(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ff76f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DATE coronavirus-tweet-id-2021-04-19-00.txt\n",
      "End DATE coronavirus-tweet-id-2021-04-25-23.txt\n",
      "x: coronavirus-tweet-id-2021-04-19-00.txt \n",
      "y+1: coronavirus-tweet-id-2021-04-26-00.txt (since range requires +1)\n",
      "\n",
      "Start VALUE=11090, \n",
      "End VALUE=11258.\n"
     ]
    }
   ],
   "source": [
    "X = 11090\n",
    "showDataCollectionStartEnd(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9ca18067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DATE coronavirus-tweet-id-2021-05-10-00.txt\n",
      "End DATE coronavirus-tweet-id-2021-05-16-23.txt\n",
      "x: coronavirus-tweet-id-2021-05-10-00.txt \n",
      "y+1: coronavirus-tweet-id-2021-05-17-00.txt (since range requires +1)\n",
      "\n",
      "Start VALUE=11618, \n",
      "End VALUE=11786.\n"
     ]
    }
   ],
   "source": [
    "X = 11618\n",
    "showDataCollectionStartEnd(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bb2b55fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DATE coronavirus-tweet-id-2021-05-24-00.txt\n",
      "End DATE coronavirus-tweet-id-2021-05-30-23.txt\n",
      "x: coronavirus-tweet-id-2021-05-24-00.txt \n",
      "y+1: coronavirus-tweet-id-2021-05-31-00.txt (since range requires +1)\n",
      "\n",
      "Start VALUE=11954, \n",
      "End VALUE=12122.\n"
     ]
    }
   ],
   "source": [
    "X = 11954\n",
    "showDataCollectionStartEnd(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c560220d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DATE coronavirus-tweet-id-2021-06-07-00.txt\n",
      "End DATE coronavirus-tweet-id-2021-06-13-23.txt\n",
      "x: coronavirus-tweet-id-2021-06-07-00.txt \n",
      "y+1: coronavirus-tweet-id-2021-06-14-00.txt (since range requires +1)\n",
      "\n",
      "Start VALUE=12290, \n",
      "End VALUE=12458.\n"
     ]
    }
   ],
   "source": [
    "X = 12290\n",
    "showDataCollectionStartEnd(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "49971312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DATE coronavirus-tweet-id-2020-04-06-00.txt\n",
      "End DATE coronavirus-tweet-id-2020-04-12-23.txt\n",
      "x: coronavirus-tweet-id-2020-04-06-00.txt \n",
      "y+1: coronavirus-tweet-id-2020-04-13-00.txt (since range requires +1)\n",
      "\n",
      "Start VALUE=1850, \n",
      "End VALUE=2018.\n",
      "1850-2018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2017"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = 1850\n",
    "showDataCollectionStartEnd(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983ca35a",
   "metadata": {},
   "source": [
    "# General Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef179630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DATE coronavirus-tweet-id-2021-09-02-00.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"Start DATE\", covidDataset[14402].split(\"/\")[7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e19c6684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHalfwayStart(yPlusOne):\n",
    "    # y based on a 7 day collection period\n",
    "    x = yPlusOne - 24 * 4\n",
    "    print(\"Start DATE\", covidDataset[x].split(\"/\")[7])\n",
    "    print(\"End DATE\", covidDataset[yPlusOne-1].split(\"/\")[7])\n",
    "    print(\"x:\", covidDataset[x].split(\"/\")[7], \"\\ny+1:\", covidDataset[yPlusOne].split(\"/\")[7], \"(since range requires +1)\")\n",
    "    print(f'{x}-{yPlusOne}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "84d64ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DATE coronavirus-tweet-id-2020-09-10-00.txt\n",
      "End DATE coronavirus-tweet-id-2020-09-13-23.txt\n",
      "x: coronavirus-tweet-id-2020-09-10-00.txt \n",
      "y+1: coronavirus-tweet-id-2020-09-14-00.txt (since range requires +1)\n",
      "5666-5762\n"
     ]
    }
   ],
   "source": [
    "getHalfwayStart(5762)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf7aacd",
   "metadata": {},
   "source": [
    "## Testing Extend Mode and Tweepy API stuff (OLD -- SCRIPT SINCE UPDATED)\n",
    "\n",
    "\n",
    "[SKIP THIS SECTION](#skip2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a02ed71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script collects data from the Twitter API and stores them in .jsonl format\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "# twitter API-related\n",
    "import tweepy\n",
    "from tqdm import tqdm\n",
    "from twarc import Twarc\n",
    "import logging\n",
    "\n",
    "\n",
    "def LOG_insert(file, format, text, level):\n",
    "    '''\n",
    "    https://stackoverflow.com/questions/49580313/create-a-log-file\n",
    "    '''\n",
    "    infoLog = logging.FileHandler(file)\n",
    "    infoLog.setFormatter(format)\n",
    "    logger = logging.getLogger(file)\n",
    "    logger.setLevel(level)\n",
    "\n",
    "    if not logger.handlers:\n",
    "        logger.addHandler(infoLog)\n",
    "        if (level == logging.INFO):\n",
    "            logger.info(text)\n",
    "        if (level == logging.ERROR):\n",
    "            logger.error(text)\n",
    "        if (level == logging.WARNING):\n",
    "            logger.warning(text)\n",
    "\n",
    "    infoLog.close()\n",
    "    logger.removeHandler(infoLog)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def setupAPI():\n",
    "    '''\n",
    "    Set up to access Twitter API\n",
    "    '''\n",
    "    # Assign developer keys\n",
    "    consumer_key = 'kjx6p3d0Mogz4A55BR4ntK1hd'\n",
    "    consumer_secret = '6wOeJIvRq3rMbMTkxFQWg449Grr3tK3WxA59QaZk57H3YkrURz'\n",
    "    access_token = '1513266361975414786-SgaPBBR3BebNzpgqTZW1uerChqmb1t'\n",
    "    access_token_secret = '4CZGPLt9n8hogFZ2ICwXOFr8Uke7XRhuBrjKyJ1ZdHWka'\n",
    "    \n",
    "    ## Jenny's key\n",
    "#     consumer_key = 'Hdzqjxf3mVyw5DQLUISQO8Dsz'\n",
    "#     consumer_secret = '9NN8pQz1gKfk8wIy8VnPXM2TWtvmvnW3n19rAavuo5MGiirDey'\n",
    "#     access_token = '1345900794625847301-pPqmLUdewBlbRx5awibCmvajKh6qnK'\n",
    "#     access_token_secret = 'bVVGLYrMxqssj1RkEUigABAd5mBZ9i4RL1nP6j6tbeDmm'\n",
    "\n",
    "    # authorization of consumer key and consumer secret\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "\n",
    "    # set access to user's access key and access secret\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "    # calling the api\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    return api\n",
    "\n",
    "\n",
    "def fetchAllTextFileURLs(time_range):\n",
    "    files = []\n",
    "    base_url = 'https://raw.githubusercontent.com/echen102/COVID-19-TweetIDs/master/'\n",
    "    prefix = 'coronavirus-tweet-id'\n",
    "    dates = list(range(1, 32))  # day 1 to 31\n",
    "    hours = list(range(24))  # hour 0 to 23\n",
    "\n",
    "    for yyyyMM in time_range:\n",
    "        for date in dates:\n",
    "            date = f'0{date}' if date < 10 else f'{date}'\n",
    "            for hour in hours:\n",
    "                hour = f'0{hour}' if hour < 10 else f'{hour}'\n",
    "                fileURL = f'{base_url}{yyyyMM}/{prefix}-{yyyyMM}-{date}-{hour}.txt'\n",
    "                files.append(fileURL)\n",
    "\n",
    "                # print(fileURL)\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def getTweetIDsFrom(txtFile):\n",
    "    '''\n",
    "    Retrieves tweet IDs from the text file's URL and stores in list\n",
    "    '''\n",
    "    tweetList = []\n",
    "    response = requests.get(txtFile)  # requests raw file from Github\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        content = response.content.decode('utf-8')\n",
    "        tweetList = content.split()\n",
    "\n",
    "    return tweetList\n",
    "\n",
    "# keyword helper functions\n",
    "\n",
    "\n",
    "def containsKeyword(text, keywords):\n",
    "    '''\n",
    "    Lowercases tweet body and checks if a word is located in the keywords list.\n",
    "    '''\n",
    "\n",
    "    loweredText = [word.lower() for word in text.split()]\n",
    "    textSet = set(loweredText)\n",
    "\n",
    "    intersection = textSet & keywords\n",
    "\n",
    "    return False if not intersection else True\n",
    "\n",
    "# helper functions used for saveTransportationTweets()\n",
    "\n",
    "\n",
    "def fetchStartAndEndDate(tweetArr, count):\n",
    "    '''\n",
    "    Returns the first and last tweet in the dataset\n",
    "    in the format YEAR-MONTH-DATE-HOUR to YEAR-MONTH-DATE-HOUR \n",
    "    '''\n",
    "    startTimeStr = tweetArr[0][\"created_at\"]\n",
    "    s = datetime.datetime.strptime(startTimeStr, '%a %b %d %H:%M:%S %z %Y')\n",
    "    sTime = s.strftime(\"%H:%M:%S\")\n",
    "    # print(\"s\",sTime)\n",
    "    endTimeStr = tweetArr[count-1][\"created_at\"]\n",
    "    e = datetime.datetime.strptime(endTimeStr, '%a %b %d %H:%M:%S %z %Y')\n",
    "    eTime = e.strftime(\"%H:%M:%S\")\n",
    "    # print(\"e\",eTime)\n",
    "\n",
    "    dateRange = f'Date Range: {s.year}-{s.month}-{s.day}-{s.hour} {sTime} to {e.year}-{e.month}-{e.day} {eTime}'\n",
    "\n",
    "    return dateRange\n",
    "\n",
    "\n",
    "def formatFileName(tweetArr):\n",
    "    '''\n",
    "    Formats the file name of the json files according to the first and last tweet in the dataset\n",
    "    using the prefix \"covid-mobility-tweet-starting\" followed by YEAR-MONTH-DATE~{time}, where time is the \n",
    "    time of the first tweet collected in the file.\n",
    "    '''\n",
    "    startTimeStr = tweetArr[0][\"created_at\"]\n",
    "    s = datetime.datetime.strptime(startTimeStr, '%a %b %d %H:%M:%S %z %Y')\n",
    "    sTime = s.strftime(\"%H:%M:%S\")\n",
    "    base_path = f'covid-mobility-tweet-starting-{s.year}-{s.month}-{s.day}'\n",
    "\n",
    "    filename_with_time = f'{base_path}~{sTime}.jsonl'\n",
    "\n",
    "    formatLOG = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "    LOG_insert(\"./collection-logs/collect-01182021-01242021.log\", formatLOG,\n",
    "               f'!json file: {filename_with_time} created', logging.INFO)\n",
    "\n",
    "    return filename_with_time\n",
    "\n",
    "def writeToJsonlFile(tweetArr, dateRange, filename):\n",
    "    '''\n",
    "    Writes a list of tweets to a given .jsonl file. Note that .jsonl\n",
    "    and .json differ in structure.\n",
    "    '''\n",
    "    # folder path\n",
    "    filepath = './collection-tweets/collect-01182021-01242021/'+filename\n",
    "    with open(filepath, 'w') as outfile:\n",
    "        # dumps the date range in json format\n",
    "        outfile.write(f'{{{dateRange}}}\\n')\n",
    "        for entry in tweetArr:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "# iterates through + saves the tweets in .jsonl format\n",
    "\n",
    "\n",
    "def saveTransportationTweets(api, tweetIDs, keywords):\n",
    "    '''\n",
    "    Iterates through list of tweets and identifies tweets containing keywords. \n",
    "\n",
    "    When the number of transportation tweets surpasses 50, save the current tweets \n",
    "    as a jsonl file and reset the tweetArr variable.\n",
    "    '''\n",
    "    tweetArr = []\n",
    "    count = 0\n",
    "    for tweet in tweetIDs:\n",
    "        # save json file and create new one\n",
    "        if count == 50:\n",
    "            # save date of first and last tweet\n",
    "            dateRange = fetchStartAndEndDate(tweetArr, count)\n",
    "            filename = formatFileName(tweetArr)  # format file name\n",
    "            # save json as a json file\n",
    "            writeToJsonlFile(tweetArr, dateRange, filename)\n",
    "            # reset 'global' vars\n",
    "            tweetArr = []\n",
    "            count = 0\n",
    "        try:\n",
    "            fetchedTweet = api.get_status(tweet)\n",
    "\n",
    "            # search for keywords in tweet text\n",
    "            if containsKeyword(fetchedTweet.text, keywords):\n",
    "                tweetArr.append(fetchedTweet._json)\n",
    "                count += 1  # maintain counter to know when the json file reaches 50 COVID-19+Transportation tweets\n",
    "                print(f\"COVID-19+Transportation Tweet #{count} at {fetchedTweet._json['created_at']}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    # if loop exits befor count == 50\n",
    "    if count > 0:\n",
    "        print(\"Total Tweet Count obtained:\", count)\n",
    "        formatLOG = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "        LOG_insert(\"./collection-logs/collect-01182021-01242021.log\", formatLOG,\n",
    "                   f\"Total Tweet Count obtained: {count}. Start writing to .jsonl file\", logging.INFO)\n",
    "        # save date of first and last tweet\n",
    "        dateRange = fetchStartAndEndDate(tweetArr, count)\n",
    "        filename = formatFileName(tweetArr)  # format file name\n",
    "\n",
    "        # save json as a json file\n",
    "        writeToJsonlFile(tweetArr, dateRange, filename)\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     # Sets up Twitter API\n",
    "#     api = setupAPI()\n",
    "\n",
    "#     # Transform keywords list\n",
    "#     keywords = pd.read_csv('./cs315_keywords.csv')\n",
    "#     # lowercase all keyword strings\n",
    "#     keywords['public transport'] = keywords['public transport'].str.lower()\n",
    "#     keywords['motorized'] = keywords['motorized'].str.lower()\n",
    "#     keywords['non-motorized'] = keywords['non-motorized'].str.lower()\n",
    "\n",
    "#     transit = keywords['public transport'].tolist()\n",
    "#     motorized = keywords['motorized'].tolist()\n",
    "#     nonmotorized = keywords['non-motorized'].tolist()\n",
    "#     keywords = set(transit + motorized + nonmotorized)\n",
    "\n",
    "#     time_range = ['2020-01', '2020-02', '2020-03', '2020-04', '2020-05', '2020-06', '2020-07', '2020-08', '2020-09', '2020-10', '2020-11', '2020-12',\n",
    "#                   '2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12',\n",
    "#                   '2022-01', '2022-02', '2022-03', '2022-04']\n",
    "\n",
    "#     covidDataset = fetchAllTextFileURLs(time_range)\n",
    "#     # data collection starts from 1/21/2020 at 22:00.\n",
    "#     covidDataset = covidDataset[502:]\n",
    "\n",
    "#     '''\n",
    "#     Note that the `covidDataset` contains each month's 24 (hourly) x 31 (daily) urls. \n",
    "#     Each month is thus 31*24=744 files apart from the next month. We remove the first \n",
    "#     24*21-2 = 502 files because date collection began on 1/21/2020 at 22:00.\n",
    "\n",
    "#     Data collection for the month of January, 2020 ran from 1/21/2020 to 1/31/2020, \n",
    "#     the 502th index to the 743 index of our covid dataset\n",
    "#     We iterate over all 24 hours and all '31' days (regardless of month)\n",
    "#     To find the entire month of data, the equation is Y = 744X + 242\n",
    "    \n",
    "#     Thus the range should be: covidDataset[744(X-2)+242: 744(X-1)+242] \n",
    "#                                         where X = month # for X > 1\n",
    "\n",
    "#     e.g. For April 2020: X = 4\n",
    "#         covidDataset[744(4-2)+242: 744(4-1)+242] = covidDataset[1730:2474]\n",
    "\n",
    "#     Or to find a specific day to start from: Y=W*24*31\n",
    "\n",
    "#     '''\n",
    "\n",
    "#     # data collection starts from 1/18/2020 at 00:00 to 1/24/2021 at 23:00.\n",
    "#                                #[0:end+1]\n",
    "#     selectedRange = covidDataset[8834:9002]\n",
    "\n",
    "#     for file in selectedRange:\n",
    "#         tweetIDs = getTweetIDsFrom(file)\n",
    "#         if len(tweetIDs) > 0:\n",
    "#             saveTransportationTweets(api, tweetIDs, keywords)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67c40f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bb57d194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11228\n",
      "Police registered 1,336 offences of illegal transportation so far and seized 93,174 vehicles\n",
      "#lockdownviolationâ€¦ https://t.co/opZklzY5bV\n",
      "1219755883690774529\n",
      "21813\n",
      "Breaking: The CDC is expected to announce the first case of the new strain of coronavirus, or nCov, in Washington state in the United States.\n",
      "RT @PMBreakingNews: Breaking: The CDC is expected to announce the first case of the new strain of coronavirus, or nCov, in Washington stateâ€¦\n"
     ]
    }
   ],
   "source": [
    "api = setupAPI()\n",
    "tweetList = getTweetIDsFrom('https://raw.githubusercontent.com/echen102/COVID-19-TweetIDs/master/2020-01/coronavirus-tweet-id-2020-01-21-22.txt') \n",
    "\n",
    "fetchedTweet = api.get_status('1286201656539922437')\n",
    "print(len(str(fetchedTweet)))\n",
    "print(fetchedTweet.text)\n",
    "    \n",
    "for tweet in tweetList[:1]:\n",
    "    print(tweet)\n",
    "    fetchedTweet2 = api.get_status(tweet, tweet_mode=\"extended\")\n",
    "    print(len(str(fetchedTweet2)))\n",
    "    rt = fetchedTweet2.retweeted_status\n",
    "    print(rt.full_text)\n",
    "    print(fetchedTweet2.full_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bf217026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched 1: dict_keys(['created_at', 'id', 'id_str', 'full_text', 'truncated', 'display_text_range', 'entities', 'source', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'is_quote_status', 'retweet_count', 'favorite_count', 'favorited', 'retweeted', 'possibly_sensitive', 'possibly_sensitive_appealable', 'lang'])\n",
      "fetched 2: dict_keys(['created_at', 'id', 'id_str', 'full_text', 'truncated', 'display_text_range', 'entities', 'source', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'retweeted_status', 'is_quote_status', 'retweet_count', 'favorite_count', 'favorited', 'retweeted', 'lang'])\n",
      "nope\n"
     ]
    }
   ],
   "source": [
    "fetchedTweet = api.get_status('1286201656539922437', tweet_mode=\"extended\") # no retweet\n",
    "fetchedTweet2 = api.get_status('1219755883690774529', tweet_mode=\"extended\") # yes retweet\n",
    "# print(fetchedTweet2._json['full_text'])\n",
    "# print(fetchedTweet2.retweeted_status._json['full_text'])\n",
    "\n",
    "# print(fetchedTweet2._json['full_text'])\n",
    "print(\"fetched 1:\", fetchedTweet._json.keys())\n",
    "# print(fetchedTweet2)\n",
    "print(\"fetched 2:\", fetchedTweet2._json.keys())\n",
    "\n",
    "if 'retweeted_status' in fetchedTweet._json:\n",
    "    print(\"works\")\n",
    "    print(fetchedTweet._json['retweeted_status'])\n",
    "else:\n",
    "    print(\"nope\")\n",
    "\n",
    "# print(fetchedTweet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "dfdd11fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTransportationTweets(api, tweetIDs, keywords):\n",
    "    '''\n",
    "    Iterates through list of tweets and identifies tweets containing keywords. \n",
    "\n",
    "    When the number of transportation tweets surpasses 50, save the current tweets \n",
    "    as a jsonl file and reset the tweetArr variable.\n",
    "    '''\n",
    "    tweetArr = []\n",
    "    count = 0\n",
    "    for tweet in tweetIDs:\n",
    "        # save json file and create new one\n",
    "        if count == 50:\n",
    "            # save date of first and last tweet\n",
    "            dateRange = fetchStartAndEndDate(tweetArr, count)\n",
    "            filename = formatFileName(tweetArr)  # format file name\n",
    "            # save json as a json file\n",
    "            writeToJsonlFile(tweetArr, dateRange, filename)\n",
    "            # reset 'global' vars\n",
    "            tweetArr = []\n",
    "            count = 0\n",
    "        try:\n",
    "            fetchedTweet = api.get_status(tweet, tweet_mode=\"extended\")\n",
    "            tweetText = fetchedTweet.full_text\n",
    "            \n",
    "            # if the tweet is a retweet, get extended text from the retweet Status: https://docs.tweepy.org/en/stable/extended_tweets.html\n",
    "            if 'retweeted_status' in fetchedTweet._json:\n",
    "                tweetText = fetchedTweet.retweeted_status.full_text\n",
    "\n",
    "            # search for keywords in tweet text\n",
    "            if containsKeyword(tweetText, keywords):\n",
    "                tweetArr.append(fetchedTweet._json)\n",
    "                print(tweetText)\n",
    "                count += 1  # maintain counter to know when the json file reaches 50 COVID-19+Transportation tweets\n",
    "                print(f\"COVID-19+Transportation Tweet #{count} at {fetchedTweet._json['created_at']}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    # if loop exits befor count == 50\n",
    "    if count > 0:\n",
    "        print(\"Total Tweet Count obtained:\", count)\n",
    "        formatLOG = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "        LOG_insert(\"./collection-logs/collect-01182021-01242021.log\", formatLOG,\n",
    "                   f\"Total Tweet Count obtained: {count}. Start writing to .jsonl file\", logging.INFO)\n",
    "        # save date of first and last tweet\n",
    "        dateRange = fetchStartAndEndDate(tweetArr, count)\n",
    "        filename = formatFileName(tweetArr)  # format file name\n",
    "\n",
    "        # save json as a json file\n",
    "        writeToJsonlFile(tweetArr, dateRange, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8bfe49b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today, taxpayer funded ads from the Ontario government will run during the Super Bowl. Leaving aside everything else that wrong with this, imo, the commercial ends, troublingly, with this statement:\n",
      "\n",
      "\"Until we all get the vaccine, stay home, save lives.\"\n",
      "https://t.co/wk3GMY9O1A\n",
      "COVID-19+Transportation Tweet #1 at Mon Feb 08 01:25:07 +0000 2021\n",
      "Iâ€™m gonna try and run today.  Walked up my stairs last night and was out of breath... quarantine eating is ruining my chances to outrun zombies. #COVID19\n",
      "COVID-19+Transportation Tweet #2 at Sat Mar 28 13:07:52 +0000 2020\n",
      "Due to unplanned lockdown, thousands of labours are walking hundred of kilometres with kids, &amp; women without food &amp; shelter just to  reach their native places. But here the minister who was entrusted responsibility to tackle #COVIDãƒ¼19 , asking people to watch mythological serial\n",
      "COVID-19+Transportation Tweet #3 at Sat Mar 28 05:54:58 +0000 2020\n",
      "VIDEO: T-Rex spotted walking his dog in Inverness https://t.co/xgSO4ULbwL #coronavirus #covid19\n",
      "COVID-19+Transportation Tweet #4 at Sat Mar 28 05:29:19 +0000 2020\n",
      "Peeps buying bread as though it was running out? Donâ€™t! #COVID19 #Malaysia #bread Massimo is my brand though ðŸ˜¢ https://t.co/flh87TJA3V\n",
      "COVID-19+Transportation Tweet #5 at Sat Mar 28 13:07:52 +0000 2020\n",
      "Total Tweet Count obtained: 5\n"
     ]
    }
   ],
   "source": [
    "api = setupAPI()\n",
    "tweetIDs = tweetList[:10]\n",
    "keywords = pd.read_csv('./cs315_keywords.csv')\n",
    "# lowercase all keyword strings\n",
    "keywords['public transport'] = keywords['public transport'].str.lower()\n",
    "keywords['motorized'] = keywords['motorized'].str.lower()\n",
    "keywords['non-motorized'] = keywords['non-motorized'].str.lower()\n",
    "transit = keywords['public transport'].tolist()\n",
    "motorized = keywords['motorized'].tolist()\n",
    "nonmotorized = keywords['non-motorized'].tolist()\n",
    "keywords = set(transit + motorized + nonmotorized)\n",
    "\n",
    "saveTransportationTweets(api, ['1358587631781642241', '1243887532863107072', '1243778587427131394', '1243772134616432640', '1243887532791582721'], keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377113af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4d9e15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
